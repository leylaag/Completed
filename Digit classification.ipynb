{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6UHmLYVhWAN"
   },
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03M_JSg3hWAO"
   },
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "* Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "* Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Finally, if you'd like to get started with Tensorflow, you can read through this tutorial: https://www.tensorflow.org/tutorials/keras/basic_classification. It uses a dataset called \"fashion_mnist\", which is identical in structure to the original digit mnist, but uses images of clothing rather than images of digits. The number of training examples and number of labels is the same. In fact, you can simply replace the code that loads \"fashion_mnist\" with \"mnist\" and everything should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO1t0ypThWAR"
   },
   "source": [
    "Load the data. Notice that the data gets partitioned into training, development, and test sets. Also, a small subset of the training data called mini_train_data and mini_train_labels gets defined, which you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yK9DacchWAS"
   },
   "outputs": [],
   "source": [
    "# Load the digit data from https://www.openml.org/d/554 or from default local location '~/scikit_learn_data/...'\n",
    "X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False)\n",
    "\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atc2JpWKhWAV"
   },
   "source": [
    "### Part 1:\n",
    "\n",
    "Show a 10x10 grid that visualizes 10 examples of each digit.\n",
    "\n",
    "Notes:\n",
    "* You can use `plt.rc()` for setting the colormap, for example to black and white.\n",
    "* You can use `plt.subplot()` for creating subplots.\n",
    "* You can use `plt.imshow()` for rendering a matrix.\n",
    "* You can use `np.array.reshape()` for reshaping a 1D feature vector into a 2D matrix (for rendering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "436UeH7JhWAW"
   },
   "outputs": [],
   "source": [
    "alldigits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "def P1(num_examples=10):\n",
    "\n",
    "\n",
    "### STUDENT START ###\n",
    "    numrow = 1\n",
    "    numcol = num_examples\n",
    "\n",
    "##### TEST ###   \n",
    "#numrow = 2\n",
    "#numcol = 2\n",
    "#fig, axes = plt.subplots(2,2) \n",
    "#pic[0]\n",
    "#axes[0,0].imshow(example[0].reshape(28,28))\n",
    "#axes[0,1].imshow(example[1].reshape(28,28))\n",
    "#plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(numrow,numcol) \n",
    "    for i in range(numcol):\n",
    "        axes[i].imshow(X0[i,].reshape(28,28))\n",
    "        axes[i].xaxis.set_visible(False)\n",
    "        axes[i].yaxis.set_visible(False)\n",
    "    plt.show()\n",
    "### STUDENT END ###\n",
    "\n",
    "for digit in alldigits:\n",
    "    X0 = mini_train_data[mini_train_labels == digit]\n",
    "#    X0[:10,]\n",
    "    P1(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMQAHr7QhWAX"
   },
   "source": [
    "### Part 2:\n",
    "\n",
    "Produce k-Nearest Neighbors models with k $\\in$ [1,3,5,7,9].  Evaluate and show the accuracy of each model. For the 1-Nearest Neighbor model, additionally show the precision, recall, and F1 for each label. Which digit is the most difficult for the 1-Nearest Neighbor model to recognize?\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
    "* You can use `classification_report` to get precision, recall, and F1 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-it5pn8-hWAY"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "def P2(k_values):\n",
    "\n",
    "\n",
    "### STUDENT START ###\n",
    "    for i in k_values:\n",
    "        model = KNeighborsClassifier(n_neighbors=i)\n",
    "        model.fit(mini_train_data, mini_train_labels)\n",
    "        dev_predicted_labels = model.predict(dev_data)\n",
    "        out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "        print(\"k=%d: Accuracy ... \" % i,out['accuracy'])\n",
    "        if (i == 1):\n",
    "#           extract all f1-scores\n",
    "            scores = []\n",
    "            for j in alldigits:\n",
    "                scores.append(out[j]['f1-score'])\n",
    "                print('f1-score for ',j, out[j]['f1-score'])\n",
    "#           find index(es) of minimum \n",
    "            indexes = [k for k, x in enumerate(scores) if x == min(scores)]\n",
    "            print(\"     Most difficult digit(s): \", indexes) \n",
    "### STUDENT END ###\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "P2(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZc9gzn5hWAZ"
   },
   "source": [
    "ANSWER: The answer is the one with the lowest f1-score, the digit 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b6YEAzzhWAa"
   },
   "source": [
    "### Part 3:\n",
    "\n",
    "Produce 1-Nearest Neighbor models using training data of various sizes.  Evaluate and show the performance of each model.  Additionally, show the time needed to measure the performance of each model.\n",
    "\n",
    "Notes:\n",
    "* Train on subsets of the train set.  For each subset, take just the first part of the train set without re-ordering.\n",
    "* Evaluate on the dev set.\n",
    "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
    "* You can use `time.time()` to measure elapsed time of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEpNzDEjhWAa"
   },
   "outputs": [],
   "source": [
    "import time \n",
    "def P3(train_sizes, accuracies):\n",
    "\n",
    "### STUDENT START ###\n",
    "    k=1\n",
    "    for s in train_sizes:\n",
    "        model = KNeighborsClassifier(n_neighbors=k)#, algorithm='kd_tree', leaf_size=1000)\n",
    "        traindata = train_data[:s]\n",
    "        trainlabels = train_labels[:s]\n",
    "        model.fit(traindata, trainlabels)\n",
    "        time0 = time.time()\n",
    "        dev_predicted_labels = model.predict(dev_data)\n",
    "        time1 = time.time() - time0\n",
    "        out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "        acc = out[\"accuracy\"]\n",
    "        accuracies.append(acc)\n",
    "        print(\"train size %d: \" % s, \"\\n elapsed time {:.3f} , Accuracy {:.3f} \".format(time1,acc))\n",
    "### STUDENT END ###\n",
    "\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600]\n",
    "#train_sizes = [100,200, 400, 800, 1600, 3200]\n",
    "#train_sizes = [100]\n",
    "accuracies = []\n",
    "P3(train_sizes, accuracies)\n",
    "#print(\"accuracies: %5.3f\"% (accuracies))\n",
    "print('\\nAccuracies')\n",
    "print(', '.join('{:.3f}'.format(f) for f in accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times displayed are for model.predict(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B56lVsKNhWAc"
   },
   "source": [
    "### Part 4:\n",
    "\n",
    "Produce a linear regression model that predicts accuracy of a 1-Nearest Neighbor model given training set size. Show $R^2$ of the linear regression model.  Show the accuracies predicted for training set sizes 60000, 120000, and 1000000.  Show a lineplot of actual accuracies and predicted accuracies vs. training set size over the range of training set sizes in the training data.  What's wrong with using linear regression here?\n",
    "\n",
    "Apply a transformation to the predictor features and a transformation to the outcome that make the predictions more reasonable.  Show $R^2$ of the improved linear regression model.  Show the accuracies predicted for training set sizes 60000, 120000, and 1000000.  Show a lineplot of actual accuracies and predicted accuracies vs. training set size over the range of training set sizes in the training data - be sure to display accuracies and training set sizes in appropriate units.\n",
    "\n",
    "Notes:\n",
    "* Train the linear regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
    "* Evaluate the linear regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
    "* You can use `LinearRegression` to produce a linear regression model.\n",
    "* Remember that the sklearn `fit()` functions take an input matrix X and output vector Y. So, each input example in X is a vector, even if it contains only a single value.\n",
    "* Hint re: predictor feature transform: Accuracy increases with training set size logarithmically.\n",
    "* Hint re: outcome transform: When y is a number in range 0 to 1, then odds(y)=y/(1-y) is a number in range 0 to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xE_qIJghWAc"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def P4():\n",
    "\n",
    "### STUDENT START ###\n",
    "    sizes=np.array(train_sizes).reshape(-1,1)\n",
    "    linreg = LinearRegression(fit_intercept = True, copy_X = True).fit(sizes,accuracies)\n",
    "    pred=linreg.predict(np.array(sizes))\n",
    "    #p.show\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(sizes, accuracies, c='blue', label=\"actual accuracies\")\n",
    "    ax.plot(sizes, pred, c='green', label=\"fitted accuracies\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.title.set_text('accuracies = a.sizes + b')\n",
    "\n",
    "    odds_accuracies = np.array(accuracies) / (1-np.array(accuracies))\n",
    "\n",
    "    loglinreg = LinearRegression(fit_intercept = True, copy_X = True).fit(np.log(sizes),odds_accuracies)\n",
    "    logpred=loglinreg.predict(np.array(np.log(sizes)))\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.scatter(np.log(sizes), odds_accuracies, c='red', label=\"odds(actual accuracies) versus ln(sizes)\")\n",
    "    ax1.plot(np.log(sizes), logpred, c='green', label=\"fitted odds(accuracies) as function of ln(sizes)\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    ax1.title.set_text('odds(accuracies) = a.ln(sizes) + b')\n",
    "\n",
    "    fig.show()\n",
    "    fig1.show()\n",
    "    print(\"Linear Regression r squared: \",linreg.score(sizes,accuracies))\n",
    "    print(\"Log linear Regression r squared: \",loglinreg.score(np.log(sizes),odds_accuracies))\n",
    "\n",
    "    larger = [60000,120000,1000000]\n",
    "    newsizes=np.array(larger).reshape(-1,1)\n",
    "    newpred = loglinreg.predict(np.array(np.log(newsizes)))\n",
    "    newpred = newpred/(1+newpred)\n",
    "    print(\"Hypothetical training sizes: \",larger)\n",
    "    print(\"Their predicted accuracies\", newpred)\n",
    "    print(\"Their predicted accuracies\")\n",
    "    print(', '.join('{:.3f}'.format(f) for f in newpred))\n",
    "### STUDENT END ###\n",
    "\n",
    "P4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYYYL9cGhWAe"
   },
   "source": [
    "ANSWER:For training sizes 60,000, 120,000 and 1,000,000 the regression gives accuracies of 0.981, 0.983 and 0.987 respectively. Note that: \n",
    "\n",
    "1- for a training size of 60,000 the fitted accuracy is lower than the actual accuracy for training size = 25,600. That is because, as can be seen on graph above, the regression underestimates the accuracy for larger training sizes. \n",
    "\n",
    "2- As can be seen in top graph above, as training size increases the relative gain in accuracy goes down (negative second derivative) indicating that at some point increasing training size can be counterproductive. That limit must depend on the accuracy reqired by the problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geAQJjGRhWAe"
   },
   "source": [
    "### Part 5:\n",
    "\n",
    "Produce a 1-Nearest Neighbor model and show the confusion matrix. Which pair of digits does the model confuse most often? Show the images of these most often confused digits.\n",
    "\n",
    "Notes:\n",
    "- Train on the mini train set.\n",
    "- Evaluate performance on the dev set.\n",
    "- You can use `confusion_matrix()` to produce a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bq36xaQohWAf"
   },
   "outputs": [],
   "source": [
    "def P5():\n",
    "\n",
    "### STUDENT START ###\n",
    "        # confusion matrix\n",
    "        model = KNeighborsClassifier(n_neighbors=1)\n",
    "        model.fit(mini_train_data, mini_train_labels)\n",
    "        dev_predicted_labels = model.predict(dev_data)\n",
    "        out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "        acc = out[\"accuracy\"]\n",
    "        cm = confusion_matrix(dev_labels, dev_predicted_labels)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = alldigits)\n",
    "        disp.plot()\n",
    "\n",
    "        #find most confused digits\n",
    "        X0 = cm\n",
    "        for i in range(10):\n",
    "            X0[i,i] = 0\n",
    "            for j in range(i,10):\n",
    "                X0[i,j] = cm[i,j]+cm[j,i]\n",
    "                X0[j,i] = 0\n",
    "        #print(X0)\n",
    "        #find index(es) of maximum \n",
    "        ind = np.unravel_index(np.argmax(X0, axis=None), X0.shape) \n",
    "        print(\"Most confused digits: \", ind) \n",
    "        num_most_confused = np.max(X0, axis=None)\n",
    "        \n",
    "        #print most confused digits\n",
    "        d0 = alldigits[ind[0]]\n",
    "        d1 = alldigits[ind[1]]\n",
    "        fig, axes = plt.subplots(num_most_confused,2) \n",
    "        fig.set_size_inches(5,10)\n",
    "\n",
    "        j = 0\n",
    "        i = 0\n",
    "        while (i < dev_labels.shape[0]):\n",
    "            if dev_labels[i] == d0:\n",
    "                if dev_predicted_labels[i] == d1:\n",
    "                    axes[j,0].imshow(dev_data[i].reshape(28,28))\n",
    "                    axes[j,0].xaxis.set_visible(False)\n",
    "                    axes[j,0].yaxis.set_visible(False)\n",
    "                    axes[j,1].text(-0.15, 0.5, 'Predicted:'+d1,  \n",
    "                                   fontsize = 12, fontweight = 'bold', \n",
    "                                   horizontalalignment='center', verticalalignment='center', transform=axes[j,1].transAxes)\n",
    "                    axes[j,1].xaxis.set_visible(False)\n",
    "                    axes[j,1].yaxis.set_visible(False)\n",
    "                    axes[j,1].axis('off')\n",
    "                    j += 1\n",
    "            elif dev_labels[i] == d1:        \n",
    "                if dev_predicted_labels[i] == d0:\n",
    "                    axes[j,0].imshow(dev_data[i].reshape(28,28))\n",
    "                    axes[j,0].xaxis.set_visible(False)\n",
    "                    axes[j,0].yaxis.set_visible(False)\n",
    "                    axes[j,1].text(-0.15, 0.5, 'Predicted:'+d0,fontsize = 12, fontweight = 'bold',\n",
    "                    horizontalalignment='center', verticalalignment='center', transform=axes[j,1].transAxes)\n",
    "                    axes[j,1].xaxis.set_visible(False)\n",
    "                    axes[j,1].yaxis.set_visible(False)\n",
    "                    axes[j,1].axis('off')\n",
    "                    j += 1\n",
    "            i += 1\n",
    "        plt.show()\n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "P5()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: this answer is for the largest instances of **pairs** of numbers that are confused. \n",
    " In this case, **both 4 predicted as 9, and  9 predicted as 4.**\n",
    "Note that for the image before last even I cannot tell whether it is a 4 or a 9!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgqMKb-hhWAh"
   },
   "source": [
    "### Part 6:\n",
    "\n",
    "A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian, i.e., the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur filter by just using the 8 neighboring pixels like this: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values.\n",
    "\n",
    "Pick a weight, then produce and evaluate four 1-Nearest Neighbor models by applying your blur filter in these ways:\n",
    "- Do not use the filter\n",
    "- Filter the training data but not the dev data\n",
    "- Filter the dev data but not the training data\n",
    "- Filter both training data and dev data\n",
    "\n",
    "Show the accuracies of the four models evaluated as described.  Try to pick a weight that makes one model's accuracy at least 0.9.\n",
    "\n",
    "Notes:\n",
    "* Train on the (filtered) mini train set.\n",
    "* Evaluate performance on the (filtered) dev set.\n",
    "* There are other Guassian blur filters available, for example in `scipy.ndimage.filters`. You are welcome to experiment with those, but you are likely to get the best results with the simplified version described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(weight, dataset, newset):\n",
    "### filters 8 closest neighbors using constant weight ###\n",
    "    (n,m) = dataset.shape\n",
    "    # print (n,m)\n",
    "\n",
    "    image=np.zeros((30,30))\n",
    "    newimage= np.zeros((28,28))\n",
    "    # reshape each row of dataset into a square, embed in a larger square image so that \n",
    "    # 1st and last columns are zeros and first and last row are zeros\n",
    "    # this allows to use the same formula for all cells in the image and not worry about cells on the contour\n",
    "    # each row of dataset has 28x28 = 784 elements\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        image[1:29,1:29] = dataset[i,].reshape(28,28)\n",
    "        for r in range(1,29):\n",
    "            for c in range(1,29):\n",
    "#                print(\"r \",r,\" c \",c)\n",
    "                newimage[r-1,c-1] = ( image[r,c] + \n",
    "                    weight * (image[r-1,c-1] + image[r-1,c] + image[r-1,c+1] + \n",
    "                       image[r,c-1]+ image[r,c+1] + \n",
    "                       image[r+1,c-1] + image[r+1,c] +image[r+1,c+1])) /(1+8*weight)\n",
    "        newset[i,:] = newimage.reshape(1,784)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(dataset, numcol):\n",
    "### draw numrows rows of numcol digits\n",
    "    ## dataset is a numpy array with 28x28 = 784 columns\n",
    "    ## plot first numcol rows of dataset (rows of dataset become columns of the output)\n",
    "    ## dataset is a numpy array with numcol rows and 28x28 = 784 columns\n",
    "    numcol = dataset.shape[0]\n",
    "    numrow = 1\n",
    "    fig, axes = plt.subplots(numrow,numcol) \n",
    "    for i in range(numcol):\n",
    "        axes[i].imshow(dataset[i,].reshape(28,28))\n",
    "        axes[i].xaxis.set_visible(False)\n",
    "        axes[i].yaxis.set_visible(False)\n",
    "    plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P6():\n",
    "    \n",
    "### STUDENT START ###\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "    # no filter\n",
    "    model.fit(mini_train_data, mini_train_labels)\n",
    "    dev_predicted_labels = model.predict(dev_data)\n",
    "    nofilter_out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "    print(\"Not filtered: Accuracy ... \",nofilter_out['accuracy'])\n",
    "    #extract all f1-scores\n",
    "#    scores = []\n",
    "#    for j in alldigits:\n",
    "#        scores.append(nofilter_out[j]['f1-score'])\n",
    "        #find index(es) of minimum \n",
    "#        indexes = [k for k, x in enumerate(scores) if x == min(scores)]\n",
    "        # index is same as digit\n",
    "#        print(\"     Most difficult digit(s): \", indexes) \n",
    "\n",
    "    weight = 1/10\n",
    "\n",
    "    # filter training set \n",
    "    new_train_data = np.ndarray(mini_train_data.shape) \n",
    "    blur(weight,mini_train_data,new_train_data)\n",
    "#    plot_digits(mini_train_data, 10)\n",
    "#    plot_digits(new_train_data, 10)\n",
    "    model.fit(new_train_data, mini_train_labels)\n",
    "    dev_predicted_labels = model.predict(dev_data)\n",
    "    out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "    print(\"Filtered training set: Accuracy ... \",out['accuracy'])\n",
    "    #extract all f1-scores\n",
    "#    scores = []\n",
    "#    for j in alldigits:\n",
    "#        scores.append(out[j]['f1-score'])\n",
    "        #find index(es) of minimum \n",
    "#        indexes = [k for k, x in enumerate(scores) if x == min(scores)]\n",
    "#        print(\"     Most difficult digit(s): \", indexes) \n",
    "\n",
    "    weight = 1/10\n",
    "    # filter dev data\n",
    "    model.fit(mini_train_data, mini_train_labels)\n",
    "    new_dev_data = np.ndarray(dev_data.shape) \n",
    "    blur(weight, dev_data, new_dev_data)\n",
    "#    plot_digits(dev_data, 10)\n",
    "#    plot_digits(new_dev_data, 10)\n",
    "    dev_predicted_labels = model.predict(new_dev_data)\n",
    "    out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "    print(\"Filtered dev_data: Accuracy ... \",out['accuracy'])\n",
    "    #   extract all f1-scores\n",
    " #   scores = []\n",
    " #   for j in alldigits:\n",
    " #       scores.append(out[j]['f1-score'])\n",
    "        #       find index(es) of minimum \n",
    "#        indexes = [k for k, x in enumerate(scores) if x == min(scores)]\n",
    "#        print(\"     Most difficult digit(s): \", indexes) \n",
    "    \n",
    "    # filter both training and dev data \n",
    "    model.fit(new_train_data, mini_train_labels)\n",
    "    dev_predicted_labels = model.predict(new_dev_data)\n",
    "    out = classification_report(dev_labels, dev_predicted_labels, output_dict=True)\n",
    "    print(\"Filtered training and dev: Accuracy ... \",out['accuracy'])\n",
    "    #   extract all f1-scores\n",
    "#    scores = []\n",
    "#    for j in alldigits:\n",
    "#        scores.append(out[j]['f1-score'])\n",
    "        #       find index(es) of minimum, use the fact that the data is same indexes \n",
    "#        indexes = [k for k, x in enumerate(scores) if x == min(scores)]\n",
    "#        print(\"     Most difficult digit(s): \", indexes) \n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "P6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Results above were obtained using a weight of 1/10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtgepWfAhWAk"
   },
   "source": [
    "### Part 7:\n",
    "\n",
    "Produce two Naive Bayes models and evaluate their performances.  Recall that Naive Bayes estimates P(feature|label), where each label is a categorical, not a real number.\n",
    "\n",
    "For the first model, map pixel values to either 0 or 1, representing white or black - you should pre-process the data or use `BernoulliNB`'s `binarize` parameter to set the white/black separation threshold to 0.1.  Use `BernoulliNB` to produce the model.\n",
    "\n",
    "For the second model, map pixel values to either 0, 1, or 2, representing white, gray, or black - you should pre-process the data, seting the white/gray/black separation thresholds to 0.1 and 0.9.  Use `MultinomialNB` to produce the model. \n",
    "\n",
    "Show the Bernoulli model accuracy and the Multinomial model accuracy.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* `sklearn`'s Naive Bayes methods can handle real numbers, but for this exercise explicitly do the mapping to categoricals. \n",
    "\n",
    "Does the multinomial version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGpH-4IQhWAk"
   },
   "outputs": [],
   "source": [
    "def P7():\n",
    "\n",
    "### STUDENT START ###\n",
    "    model1 = BernoulliNB(alpha=1, binarize=0.1)\n",
    "    model1.fit(mini_train_data, mini_train_labels)\n",
    "    dev_predicted_model1 = model1.predict(dev_data)\n",
    "    model1_out = classification_report(dev_labels, dev_predicted_model1,output_dict=True)\n",
    "    #print(model1_out)\n",
    "    print(\"Binomial Accuracy ... \",model1_out['accuracy'])\n",
    "\n",
    "    #model 2 \n",
    "    #build trinomial data set\n",
    "    trinom_data = np.ones(mini_train_data.shape)\n",
    "    trinom_data[mini_train_data < 0.1] = 0\n",
    "    trinom_data[mini_train_data > 0.9] = 2\n",
    "    # create model2\n",
    "    model2 = MultinomialNB(alpha=1)\n",
    "    model2.fit(trinom_data, mini_train_labels)\n",
    "    dev_predicted_model2 = model2.predict(dev_data)\n",
    "    model2_out = classification_report(dev_labels, dev_predicted_model2,output_dict=True)\n",
    "    #print(model2_out)\n",
    "    print(\"Multinomial Accuracy ... \",model2_out['accuracy'])\n",
    "### STUDENT END ###\n",
    "\n",
    "P7()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNLrgggohWAm"
   },
   "source": [
    "ANSWER: The multinomial does not help. The reason is that the original data is or should be binomial (black or white). \n",
    "    So there is no good reason to distinguish a third color. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PqjbRLg7hWAm"
   },
   "source": [
    "### Part 8:\n",
    "\n",
    "Search across several values of the LaPlace smoothing parameter (alpha) to find its effect on a Bernoulli Naive Bayes model's performance.  Show the accuracy at each alpha value.\n",
    "\n",
    "Notes:\n",
    "* Set binarization threshold to 0.\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance by 5-fold cross-validation. \n",
    "* Use `GridSearchCV(..., ..., cv=..., scoring='accuracy', iid=False)` to vary alpha and evaluate performance by cross-validation.\n",
    "* Cross-validation is based on partitions of the training data, so results will be a bit different than if you had used the dev set to evaluate performance.\n",
    "\n",
    "What is the best value for alpha? What is the accuracy when alpha is near 0? Is this what you'd expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AvZ-Wp3hWAn"
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "def P8(alphas):\n",
    "\n",
    "### STUDENT START ###\n",
    "    model = BernoulliNB(binarize=0)\n",
    "    GSCV = GridSearchCV(model, param_grid = alphas, cv=5,scoring='accuracy',verbose=0)\n",
    "    GSCV.fit(mini_train_data, mini_train_labels)\n",
    "#    print(sorted(GSCV.cv_results_.keys()))\n",
    "#    print(sorted(GSCV.cv_results_))\n",
    "#    df = pd.DataFrame(GSCV.cv_results_)\n",
    "#    print(df)\n",
    "    return GSCV    \n",
    "### STUDENT END ###\n",
    "\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = P8(alphas)\n",
    "print(\"Best alpha = \", nb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yEg9keThWAp"
   },
   "source": [
    "ANSWER: Alpha = 0.001 gives the best result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B07GDiDdhWAq"
   },
   "source": [
    "### Part 9\n",
    "\n",
    "Produce a model using Guassian Naive Bayes, which is intended for real-valued features, and evaluate performance. You will notice that it does not work so well. Diagnose the problem and apply a simple fix so that the model accuracy is around the same as for a Bernoulli Naive Bayes model. Show the model accuracy before your fix and the model accuracy after your fix.  Explain your solution.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* Consider the effects of theta and sigma.  These are stored in the model's `theta_` and `sigma_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBLbTMWChWAq"
   },
   "outputs": [],
   "source": [
    "def P9():\n",
    "### GaussianNB; change var_smoothing \n",
    "### STUDENT END ###\n",
    "    model=GaussianNB()\n",
    "    model.fit(mini_train_data,mini_train_labels)\n",
    "    dev_predicted_model = model.predict(dev_data)\n",
    "    model_out = classification_report(dev_labels, dev_predicted_model,output_dict=False)\n",
    "    print(\"BEFORE\")\n",
    "    print(model_out)\n",
    "#    model1 = GaussianNB()\n",
    "    params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "    GSCV = GridSearchCV(model, param_grid = params_NB, cv=5,scoring='accuracy',verbose=0)\n",
    "    GSCV.fit(mini_train_data, mini_train_labels)\n",
    "#    print(sorted(GSCV.cv_results_.keys()))\n",
    "#    print(sorted(GSCV.cv_results_))\n",
    "#    df = pd.DataFrame(GSCV.cv_results_)\n",
    "#    print(df)\n",
    "#    print(\"Best Var Smoothing \", GSCV.best_params_) \n",
    "    print(\"AFTER changing VAR SMOOTHING\")\n",
    "    print(\"Best Estimator \", GSCV.best_estimator_)\n",
    "    print(\"Best Score \", GSCV.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P9()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SyHTEJohWAt"
   },
   "source": [
    "ANSWER: For Var_smoothing = 0.035 the accuracy is the best: 0.799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P9_sigma_theta():\n",
    "### using sigma and/or theta\n",
    "### STUDENT END ###\n",
    "    model=GaussianNB()\n",
    "    model.fit(mini_train_data,mini_train_labels)\n",
    "    dev_predicted_model = model.predict(dev_data)\n",
    "    model_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    print(\"Accuracy before any changes... \",model_out['accuracy'])\n",
    "#    print(model_out)\n",
    "#    print(model.sigma_)\n",
    "    sigma_save = model.sigma_\n",
    "    theta_save = model.theta_\n",
    "    \n",
    "    print(\"\\nChanging SIGMA\")\n",
    "    acc = []\n",
    "    for i in range(1,11):\n",
    "        sigma_factor = i * 0.1\n",
    "        model.sigma_ = model.sigma_ * sigma_factor\n",
    "        dev_predicted_model = model.predict(dev_data)\n",
    "        model_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "#    print(\"model.sigma_ multiplied by: \", sigma_factor)\n",
    "        print(\"sigma times {:.3f}\".format(sigma_factor), \"; Accuracy ... \",model_out['accuracy'])\n",
    "        acc.append(model_out['accuracy'])\n",
    "    ind = acc.index(max(acc))\n",
    "    sigma_factor = (1+ind)*0.1\n",
    "    print(\"Best accuracy obtained for sigma_ multiplied by \",sigma_factor)\n",
    "#    print(model_out)\n",
    "\n",
    "    print(\"\\nChanging THETA\")\n",
    "    model.sigma_ = sigma_save\n",
    "    acc=[]\n",
    "    for i in range(1,11):\n",
    "        theta_factor = i * 0.25\n",
    "        model.theta_ = model.theta_ * theta_factor\n",
    "        dev_predicted_model = model.predict(dev_data)\n",
    "        model_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "        acc.append(model_out['accuracy'])\n",
    "#    print(\"model.sigma_ multiplied by: \", sigma_factor)\n",
    "        print(\"theta times \",theta_factor, \"; Accuracy ... \",model_out['accuracy'])\n",
    "    ind1 = acc.index(max(acc))\n",
    "    theta_factor = (1+ind1)*0.25\n",
    "    print(\"Best accuracy obtained for theta_ multiplied by \",theta_factor)\n",
    "    \n",
    "\n",
    "    \n",
    "#print(\"model.theta_ multiplied by: \", theta_factor,\" model.sigma_ multiplied by: \", sigma_factor)\n",
    "#    print(\"adding theta times \",theta_factor, \"; Accuracy ... \",model_out['accuracy'])\n",
    "#    print(model_out)\n",
    "\n",
    "    model.sigma_ = sigma_save * sigma_factor\n",
    "    model.theta_ = theta_save * theta_factor\n",
    "    dev_predicted_model = model.predict(dev_data)\n",
    "    model_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    print(\"\\nChanging SIGMA and THETA\")\n",
    "    print(\"For model.theta_ multiplied by: \",theta_factor,\"; and model.sigma_ multiplied by: \",sigma_factor)\n",
    "    print(\"Accuracy ... \",model_out['accuracy'])\n",
    "#    print(model_out)\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P9_sigma_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "1SyHTEJohWAt"
   },
   "outputs": [],
   "source": [
    "ANSWER:\n",
    "    \n",
    "    To improve accuracy I found that the better way was to do a grid search on var_smoothing, but I am not able to \n",
    "    explain why. I was not able to find a good explanation of why adjust the variance of one dimension would improve \n",
    "    the accuracy.\n",
    "    \n",
    "    Changing Sigma and/or Theta: I tried a similar method as the grid search by hand. \n",
    "    The best improvement accuracy is when sigma alone is reduced. \n",
    "    Larger values of sigma would be equivalent to calculating a weighted average of the feature over a larger area.\n",
    "    That would diffuse the picture, make it more fuzzy, and therefore harder to decipher "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgZMuc1VhWAt"
   },
   "source": [
    "### Part 10:\n",
    "\n",
    "Because Naive Bayes produces a generative model, you can use it to generate digit images.\n",
    "\n",
    "Produce a Bernoulli Naive Bayes model and then use it to generate a 10x20 grid with 20 example images of each digit. Each pixel output should be either 0 or 1, based on comparing some randomly generated number to the estimated probability of the pixel being either 0 or 1.  Show the grid.\n",
    "\n",
    "Notes:\n",
    "* You can use np.random.rand() to generate random numbers from a uniform distribution.\n",
    "* The estimated probability of each pixel being 0 or 1 is stored in the model's `feature_log_prob_` attribute. You can use `np.exp()` to convert a log probability back to a probability.\n",
    "\n",
    "How do the generated digit images compare to the training digit images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktii-Mp-hWAu"
   },
   "outputs": [],
   "source": [
    "def P10(num_examples):\n",
    "### use predicted joint probability to generate new images   \n",
    "\n",
    "### STUDENT START ###\n",
    "    model = BernoulliNB(alpha=1, binarize=0.1)\n",
    "    model.fit(mini_train_data, mini_train_labels)\n",
    "    dev_predicted_model = model.predict(dev_data)\n",
    "    model_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    #print(model1_out)\n",
    "    print(\"Binomial Accuracy ... \",model_out['accuracy'])\n",
    "\n",
    "    # get probabilities\n",
    "    prob = np.exp(model.feature_log_prob_)\n",
    "#    print(prob.shape)\n",
    "#    print(prob[1,])\n",
    "\n",
    "    for digit in range(10):\n",
    "        pixels = np.ones(shape=(num_examples,784))\n",
    "        for ex in range(num_examples):\n",
    "            for i in range(784):\n",
    "                # sample from prob\n",
    "                n = np.random.rand()\n",
    "                if n > prob[digit,i]:\n",
    "                    pixels[ex,i] = 0\n",
    "        plot_digits(pixels, num_examples)\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P10(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuQd1fTGhWAw"
   },
   "source": [
    "ANSWER: The generated images look worse than the training images. Could it be a coincidence? \n",
    "    A sample of size 20 is too small to arrive at a conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksHMg73uhWAx"
   },
   "source": [
    "### Part 11:\n",
    "\n",
    "Recall that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior probability of the predicted class is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior probability and accuracy.  \n",
    "\n",
    "Produce a Bernoulli Naive Bayes model.  Evaluate performance: partition the dev set into several buckets based on the posterior probabilities of the predicted classes - think of a bin in a histogram- and then estimate the accuracy for each bucket. So, for each prediction, find the bucket to which the maximum posterior probability belongs, and update \"correct\" and \"total\" counters accordingly.  Show the accuracy for each bucket.\n",
    "\n",
    "Notes:\n",
    "* Set LaPlace smoothing (alpha) to the optimal value (from part 8).\n",
    "* Set binarization threshold to 0.\n",
    "* Train on the mini train set.\n",
    "* Evaluate perfromance on the dev set.\n",
    "\n",
    "How would you characterize the calibration for this Bernoulli Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1N-St12hWAy"
   },
   "outputs": [],
   "source": [
    "def P11(buckets, correct, total):\n",
    "    \n",
    "### STUDENT START ###\n",
    "    model = BernoulliNB(alpha=0.001, binarize=0)\n",
    "    model.fit(mini_train_data, mini_train_labels)\n",
    "    dev_predicted_labels = model.predict(dev_data)\n",
    "    model_out = classification_report(dev_labels, dev_predicted_labels,output_dict=True)\n",
    "    #print(model1_out)\n",
    "    print(\"Binomial Accuracy ... \",model_out['accuracy'])\n",
    "\n",
    "    # get probabilities\n",
    "    predicted_prob = model.predict_proba(dev_data)\n",
    "    # print(predicted_prob.shape)\n",
    "    \n",
    "    # print probabilities for first digit in dev data.\n",
    "    # predicted_proba[0,i]) is the probability of the first number being 'i'\n",
    "    for i in range(10):\n",
    "        print(\"Predicted prob. of digit being \",i,\"...\", predicted_prob[0,i])\n",
    "#    print(\"Actual label: \", dev_labels[0], \"  Predicted label:\", dev_predicted_labels[0])\n",
    "\n",
    "    # sort dev_data into buckets based on their predicted probability\n",
    "    for i in range(len(dev_data)):\n",
    "        pred=int(dev_predicted_labels[i])\n",
    "        #prob is the model's predicted probability that dev_data[i] is dev_predicted_label \n",
    "        prob = predicted_prob[i][pred]\n",
    "        # if (i==0): print(prob ,\" \", i, \" \", pred)\n",
    "            \n",
    "        # for each bucket count the % of correct predictions\n",
    "        j=0\n",
    "        while j < len(buckets):\n",
    "            if prob > buckets[j]:\n",
    "                j +=1\n",
    "            else:\n",
    "                total[j] += 1\n",
    "                if dev_predicted_labels[i] == dev_labels[i]:\n",
    "                    correct[j] += 1\n",
    "                break\n",
    " \n",
    "#    print(total)\n",
    "#    print(correct)\n",
    "### STUDENT END ###\n",
    "\n",
    "    \n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "P11(buckets, correct, total)\n",
    "#print(total)\n",
    "#print(correct)\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "     accuracy = 0.0\n",
    "     if ( total[i] > 0): \n",
    "        accuracy = correct[i] / total[i]\n",
    "     print('For bucket %.13f to %.13f    total = %3d    accuracy = %.3f' % (0 if i==0 else buckets[i-1], buckets[i], total[i], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-4qQsrrhWA1"
   },
   "source": [
    "ANSWER: It is clear that the accuracy of the model is positively correlated with the predicted probability. \n",
    "    However, the accuracy is well below 0.8 for probabilities that are over 90%.  The model is weakly calibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLDISyh4hWA1"
   },
   "source": [
    "### Part 12 EXTRA CREDIT:\n",
    "\n",
    "Design new features to see if you can produce a Bernoulli Naive Bayes model with better performance.  Show the accuracy of a model based on the original features and the accuracy of the model based on the new features.\n",
    "\n",
    "Here are a few ideas to get you started:\n",
    "- Try summing or averaging the pixel values in each row.\n",
    "- Try summing or averaging the pixel values in each column.\n",
    "- Try summing or averaging the pixel values in each square block. (pick various block sizes)\n",
    "- Try counting the number of enclosed regions. (8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0)\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set (enhanced to comprise the new features).\n",
    "* Evaulate performance on the dev set.\n",
    "* Ensure that your code is well commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P7h-t2ThWA2"
   },
   "outputs": [],
   "source": [
    "def P12():\n",
    "\n",
    "### STUDENT START ###\n",
    "    \n",
    "    n = mini_train_data.shape[0] # number of rows of mini_train_set\n",
    "    x= mini_train_data.reshape(n, 28,28)\n",
    "    y = np.sum(x,axis=1)  # sum of columns\n",
    "    z = np.sum(x,axis=2)  # sum of rows\n",
    "#    print(mini_train_data.shape)\n",
    "#    print(y.shape)\n",
    "    new_train_set_1 = np.hstack([mini_train_data,z]) #add sum of rows to mini_train_data \n",
    "    new_train_set_2 = np.hstack([mini_train_data,y]) #add sum of columns to mini_train_data\n",
    "    new_train_set_3 = np.hstack([mini_train_data,z,y])  #add sum of rows and sum of columns to mini_train_data\n",
    "    \n",
    "    n = dev_data.shape[0] # number of rows of mini_train_set\n",
    "    x= dev_data.reshape(n, 28,28)\n",
    "    y = np.sum(x,axis=1)  # sum of columns\n",
    "    z = np.sum(x,axis=2)  # sum of rows\n",
    "#    print(dev_data.shape)\n",
    "#    print(y.shape)\n",
    "    new_dev_set_1 = np.hstack([dev_data,z])  #add sum of rows to dev_data \n",
    "    new_dev_set_2 = np.hstack([dev_data,y])  #add sum of columns to dev_data\n",
    "    new_dev_set_3 = np.hstack([dev_data,z,y])  #add sum of rows and sum of columns to dev_data\n",
    "    \n",
    "    # original model\n",
    "    model = BernoulliNB(alpha=1, binarize=0)\n",
    "    model.fit(mini_train_data, mini_train_labels)\n",
    "    dev_predicted_model = model.predict(dev_data)\n",
    "    model_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    print(\"Original accuracy = \",model_out['accuracy'])\n",
    "    \n",
    "    # model with sum of rows\n",
    "    model1 = BernoulliNB(alpha=1, binarize=0)\n",
    "    model1.fit(new_train_set_1, mini_train_labels)\n",
    "    dev_predicted_model = model1.predict(new_dev_set_1)\n",
    "    model1_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    print(\"With sum of rows, accuracy = \",model1_out['accuracy'])\n",
    "    \n",
    "    # model with sum of columns\n",
    "    model2 = BernoulliNB(alpha=1, binarize=0)\n",
    "    model2.fit(new_train_set_2, mini_train_labels)\n",
    "    dev_predicted_model = model2.predict(new_dev_set_2)\n",
    "    model2_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    print(\"With sum of columns, accuracy = \",model2_out['accuracy'])\n",
    "\n",
    "    # model with sum of columns and sum of rows\n",
    "    model3 = BernoulliNB(alpha=1, binarize=0)\n",
    "    model3.fit(new_train_set_3, mini_train_labels)\n",
    "    dev_predicted_model = model3.predict(new_dev_set_3)\n",
    "    model3_out = classification_report(dev_labels, dev_predicted_model,output_dict=True)\n",
    "    print(\"With sum of rows and columns, accuracy = \",model2_out['accuracy'])\n",
    "### STUDENT END ###\n",
    "\n",
    "P12()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "firstname_lastname_p1.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/MIDS-W207/Master/blob/master/Projects/firstname_lastname_p1.ipynb",
     "timestamp": 1557957807607
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
